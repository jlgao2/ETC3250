---
title: "ETC3250/ETC5250 Assignment 1"
date: "SOLUTION"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE)
```

## Marks

- Total mark ______/25
- Readability/citation  ______/5
- Reproducibility  ______/5
- Answers ______/15 

## Exercises

```{r}
# Load libraries
library(caret)
library(broom)
library(tidyverse)
```

```{r eval=FALSE}
# This is my code to make the simulated data
x <- runif(164, -10, 20)
y <- -4*x+6*x^2-100*sin(x) + rnorm(164, mean=0, sd=50)
df <- tibble(x, y)
ggplot(df, aes(x=x, y=y)) + geom_point()
saveRDS(df, file="data/cuddly_koalas.rds")
```

1. This question explores bias-variance trade-off. Read in the simulated data `cuddly_koalas.rds`. This data is generated using the following function:
$$ y = -4x + 6x^2 - 100sin(x) + \varepsilon, ~~\text{where}~~x\in [-10, 20], ~~\varepsilon\sim N(0, 50^2)$$
a. (1)Make a plot of the data, overlaying the true model.
```{r echo=FALSE}
# Read data
df <- readRDS("data/cuddly_koalas.rds")

# Compute the true model values
df <- df %>% mutate(true=-4*x+6*x^2-100*sin(x))

# Plot data and true model 
ggplot(df, aes(x=x, y=y)) + geom_point() +
  geom_line(aes(y=true), colour="blue")
```
b. (1)Break the data into a $2/3$ training and a $1/3$ test set. (Hint: You can use the function `createDataPartition` from the `caret` package.) Fit a linear model, using the training set. Compute the training MSE and test MSE. Overlay the linear model fit on a plot of the data and true model.
```{r}
# Create training and test sets
set.seed(20200318)
tr_indx <- createDataPartition(df$y, p=0.67)$Resample1
tr <- df[tr_indx,]
ts <- df[-tr_indx,]

# Fit linear model
fit1 <- lm(y~x, data=tr)
tr_aug <- augment(fit1, tr)
ts_aug <- augment(fit1, newdata=ts)
ts_aug$.resid <- ts_aug$y - ts_aug$.fitted
tr_mse <- sum(tr_aug$.resid^2)/length(tr_aug$.resid)
ts_mse <- sum(ts_aug$.resid^2)/length(ts_aug$.resid)

# Plot the data, true model and fitted model
ggplot(tr, aes(x=x, y=y)) + geom_point() +
  geom_line(aes(y=true)) + geom_line(data=tr_aug, aes(x=x, y=.fitted), colour="orange")
```

c. Now examine the behaviour of the training and test MSE, for a `loess` fit. 
    i. (1)Look up the `loess` model fit, and write a paragraph explaining how this fitting procedure works. In particular, explain what the `span` argument does. Add a (hand) sketch illustrating the method.
    **`loess` fits a polynomial model on subsets of the data. The subsets are produced using a sliding window across the `x` variable. Within each window, the model is fitted. The predicted values are combined from all of the fits, weighted by distance from the centre of the window, and aggregated to produce a fitted value at each `x`. By default, a quadratic polynomial is used.**
![](loess.png) 
    ii. (1)Compute the training and test MSE for a range of `span` values, 1, 0.5, 0.3, 0.2, 0.1, 0.05. Plot the training and test MSE against the span parameter. For each model, also make a plot of the data and fitted model. Include just the plot of the fit of the model that you think best captures the relationship between x and y.)
```{r}
span <- c(1, 0.5, 0.3, 0.2, 0.1, 0.05)
tr_mse2 <- NULL
ts_mse2 <- NULL

# Fit a loess model and compute MSEs
for (i in 1:length(span)) {
  fit2 <- loess(y~x, data=tr, span=span[i])
  tr_aug2 <- augment(fit2, tr)
  ts_aug2 <- augment(fit2, newdata=ts)
  ts_aug2$.resid <- ts_aug2$y - ts_aug2$.fitted
  trm <- sum(tr_aug2$.resid^2)/length(tr_aug2$.resid)
  tsm <- sum(ts_aug2$.resid^2, na.rm=TRUE)/
    length(ts_aug2$.resid[!is.na(ts_aug2$.resid)])
  tr_mse2 <- c(tr_mse2, trm)
  ts_mse2 <- c(ts_mse2, tsm)
}

mse_df <- tibble(span, `train MSE`=tr_mse2, `test MSE`=ts_mse2)
mse_df <- mse_df %>% pivot_longer(cols = `train MSE`:`test MSE`, names_to = "type", values_to="mse")
ggplot(mse_df, aes(x=span, y=mse, colour=type)) + 
  geom_point() +
  geom_line() + 
  scale_x_reverse() +
  ylab("MSE") +
  scale_colour_brewer("", palette="Dark2")
```
```{r eval=FALSE}
# Plot the data, true model and fitted model
ggplot(tr, aes(x=x, y=y)) + geom_point() +
  geom_line(aes(y=true)) + geom_line(data=tr_aug2, aes(x=x, y=.fitted), colour="orange")
```
    iii. (2)Write a paragraph explaining the effect of increasing the flexibility of the fit has on the training and test MSE. Indicate what you think is the optimal span value for this data. Make a plot of this optimal fit.
**As the span gets smaller, the fit approaches the true model, as indicated by the training MSE and test NSE decreasing. At some point, it begins to fit the noise in the data, to overfit, and this can be seen by test MSE increasing. Between `0.1-0.05` would be optimal span values.**
```{r}
fit_all <- loess(y~x, data=df, span=0.05)
df_all <- augment(fit_all, df)
ggplot(df, aes(x=x, y=y)) + geom_point() +
  geom_line(data=df_all, aes(x=x, y=.fitted), colour="orange")
```
d. (2)Make a sketch indicating observed data, the true model, fitted model, and indicate what the bias, variance and MSE refer to. Remember that to understand bias and variance, you need to think about taking multiple (and actually all possible) samples. Your illustration would have predictor ($x$) on the horizontal axis and response on the vertical axis. Represent and observed value with a dot, and use curves for fitted models and the true model.
**The "irreducible error" is $50^2$, as specified by the data generating process in the simulation setup. MSE is the difference between the fitted model and the observed y. Variance is the variability in $\hat{f(y)}$ between samples. Bias is the variability between the fitted model and the true model, which is sometimes referred t oas model misspecification.** 
\\
**Something like the illustration below should be drawn**
\\
![](bias-variance.png)

2. The current COVID-19 health crisis worries us all. John Hopkins University has been carefully documenting incidence, recoveries and deaths around the globe at https://github.com/CSSEGISandData/COVID-19. Read the incidence data from https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv, into R.

a. (2)The data shows cumulative counts by date for many countries. Extract the data for Australia. It is currently multiple rows corresponding to counts in different states. Pivot the data into long tidy form, and convert the text date into a date variable. Difference the days, so that you have the incidence for each day. Make a bar chart of incidence by date. Add a loess smooth to the plot.

```{r}
library(tidyverse)
library(lubridate)
library(broom)
library(tsibble)
covid_jh <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv")
covid_jh_oz <- covid_jh %>%
  filter(`Country/Region` == "Australia") %>%
  pivot_longer(cols=contains("/20"), names_to = "date") %>%
  mutate(date = mdy(date)) %>%
  group_by(date) %>%
  summarise(count = sum(value)) %>%
  mutate(yesterday = lag(count)) %>%
  mutate(dif = count -  yesterday) %>%
  filter(date < ymd("2020-04-03"))
covid_jh_oz %>%
  ggplot(aes(x=date, y=dif)) + 
    geom_col() +
    geom_smooth(se=FALSE) +
    ylab("count") + xlab("")
```

b. (3)Fit an appropriate linear model, using `glm` to the data. (Hint: ) Make a summary of the model fit, write down the model equation and a plot of the data with the model overlaid. Compute the ratio of the deviance relative to the null deviance. What does this say about the model fit? Is it a good summary of the variation in counts?

```{r}
covid_jh_oz_lm <- glm(dif~date, data=covid_jh_oz, family="poisson")
covid_jh_oz_lm
covid_jh_oz <-  augment(covid_jh_oz_lm, covid_jh_oz) %>%
  mutate(.fitted = exp(.fitted))
covid_jh_oz_new <-  covid_jh_oz %>% 
  mutate(.fitted=predict(covid_jh_oz_lm, covid_jh_oz, type="response"))

covid_jh_oz_new %>%
  ggplot(aes(x=date, y=dif)) + 
  geom_col() +
  geom_smooth(se=FALSE) +
  geom_line(aes(y=.fitted), color="red") +
  xlab("") + ylab("daily count") 
```
$$\widehat{\log_e (count)} = -2147.0316 + 0.1173 \text{date} $$
The equation would be nicer if we had converted date to "days since first case". The ratio of residual deviance to null deviance is `r  round(covid_jh_oz_lm$deviance/covid_jh_oz_lm$null.deviance, 2)`. This is a small number, which tells us that the model fits well, and explains most of the variation in count. However, what it doesn't tell us is that the fit in the most recent few days is not good - its very much an over-estimate of the actual count.

d. (1)Would the `glm` model be considered a flexible or inflexible model? **Inflexible**
e. (1)Use your model to predict the count for Apr  6. (The actual count for Apr 6 was 110.)
```{r}
predict(covid_jh_oz_lm, newdata=data.frame(date=ymd("2020-04-06")), type="response")
```

```{r eval=FALSE}
# Check Apr 6 numbers
covid_jh_oz <- covid_jh %>%
  filter(`Country/Region` == "Australia") %>%
  pivot_longer(cols=contains("/20"), names_to = "date") %>%
  mutate(date = mdy(date)) %>%
  group_by(date) %>%
  summarise(count = sum(value)) %>%
  mutate(yesterday = lag(count)) %>%
  mutate(dif = count -  yesterday) %>%
  mutate(dif7 = (count - dplyr::lag(count, 7, order_by = date))/7)

covid_jh_oz <- covid_jh_oz %>%
  mutate(.fitted = predict(covid_jh_oz_lm, covid_jh_oz, type="response"))

covid_jh_oz %>%
  ggplot(aes(x=date, y=dif)) + 
  geom_col() +
  geom_smooth(se=FALSE) +
  geom_line(aes(y=.fitted), color="red") +
  geom_line(aes(y=dif7),  colour="orange") +
  xlab("") + ylab("daily count") 
```
